## K-Nearest Neighbor

算法：

for K=1, 2,...

1. 计算未知数据点与所有已知数据样本之间的距离
2. 找出与未知数据点距离最近的K个点
3. 将这K个点的类别中占多数的类别(majority voting)分给未知数据点

评价效果最好的K 并在交叉验证集上测试

缺点：

1. 计算量较大，需要跟所有已知数据点比较
2. K值太小时，模型对数据和噪声很敏感，容易过拟合。K值太大时，容易欠拟合，准确度下降。
3. ​