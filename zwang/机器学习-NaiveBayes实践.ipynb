{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "supported-panic",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "Cassification is the process of dividing the dataset into different categories or groups by adding labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-wings",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "## 手工"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "widespread-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "lucky-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()), 'dataset\\\\titanic-dataset\\\\titanic_train.csv'))\n",
    "\n",
    "X = data.pclass.to_numpy().reshape(-1, 1)\n",
    "Y = data.survived.to_numpy()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "extra-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_c1 = np.mean(Y_train)\n",
    "p_c0 = 1 - p_c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "earned-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_c0 = X_train[Y_train==0]\n",
    "X_c1 = X_train[Y_train==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "diagnostic-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_1_c0 = np.mean(X_c0==1)\n",
    "p_2_c0 = np.mean(X_c0==2)\n",
    "p_3_c0 = np.mean(X_c0==3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "serial-staff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15402298850574714, 0.1793103448275862, 0.6666666666666666)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_1_c0,p_2_c0, p_3_c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "attractive-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_1_c1 = np.mean(X_c1==1)\n",
    "p_2_c1 = np.mean(X_c1==2)\n",
    "p_3_c1 = np.mean(X_c1==3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "musical-removal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4122448979591837, 0.22857142857142856, 0.35918367346938773)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_1_c1,p_2_c1, p_3_c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "delayed-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_c0_1 = p_c0 * p_1_c0 / (p_c0 * p_1_c0 + p_c1 * p_1_c1)\n",
    "p_c0_2 = p_c0 * p_2_c0 / (p_c0 * p_2_c0 + p_c1 * p_2_c1)\n",
    "p_c0_3 = p_c0 * p_3_c0 / (p_c0 * p_3_c0 + p_c1 * p_3_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "yellow-laser",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3988095238095238, 0.582089552238806, 0.7671957671957672)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_c0_1, p_c0_2, p_c0_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "protected-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_c1_1 = p_c1 * p_1_c1 / (p_c0 * p_1_c0 + p_c1 * p_1_c1)\n",
    "p_c1_2 = p_c1 * p_2_c1 / (p_c0 * p_2_c0 + p_c1 * p_2_c1)\n",
    "p_c1_3 = p_c1 * p_3_c1 / (p_c0 * p_3_c0 + p_c1 * p_3_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "parental-outline",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6011904761904762, 0.417910447761194, 0.23280423280423282)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_c1_1, p_c1_2, p_c1_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "voluntary-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_survived(pclass):\n",
    "    if pclass == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "hidden-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict = []\n",
    "for pclass in X_test:\n",
    "    Y_predict.append(is_survived(pclass))\n",
    "Y_predict = np.array(Y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "oriented-thomson",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6588235294117647"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0\n",
    "for i, j in zip(Y_predict, Y_test):\n",
    "    if i == j:\n",
    "        counter += 1 \n",
    "        \n",
    "accuracy = counter / len(Y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-yorkshire",
   "metadata": {},
   "source": [
    "## 自动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "other-highlight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities p(c0) and p(c1):\n",
      " [0.6397058823529415, 0.3602941176470591]\n",
      "Probabilities p(1|c0), p(2|c0), p(3|c0):\n",
      " [2.2988505747105254e-13, 0.15402298850583543, 0.17931034482765132, 0.6666666666662834]\n",
      "Probabilities p(1|c1), p(2|c1), p(3|c1):\n",
      " [4.0816326530545546e-13, 0.4122448979589189, 0.22857142857146348, 0.35918367346920943]\n"
     ]
    }
   ],
   "source": [
    "# import some preprocessing methods, such as train/test split and feature encoding, accuracy checker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "clf = CategoricalNB(alpha=1.0e-10)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "print('Probabilities p(c0) and p(c1):\\n', [np.exp(x) for x in clf.class_log_prior_.tolist()])\n",
    "print('Probabilities p(1|c0), p(2|c0), p(3|c0):\\n', [np.exp(x) for x in clf.feature_log_prob_[0][0].tolist()])\n",
    "print('Probabilities p(1|c1), p(2|c1), p(3|c1):\\n', [np.exp(x) for x in clf.feature_log_prob_[0][1].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "hungry-houston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     class  predict_proba  predict  survived\n",
      "0        3       0.232804        0         0\n",
      "1        3       0.232804        0         0\n",
      "2        3       0.232804        0         0\n",
      "3        3       0.232804        0         0\n",
      "4        3       0.232804        0         0\n",
      "..     ...            ...      ...       ...\n",
      "165      3       0.232804        0         1\n",
      "166      3       0.232804        0         0\n",
      "167      2       0.417910        0         1\n",
      "168      3       0.232804        0         0\n",
      "169      3       0.232804        0         0\n",
      "\n",
      "[170 rows x 4 columns]\n",
      "Accuracy: 0.6588235294117647\n"
     ]
    }
   ],
   "source": [
    "Y_predict = clf.predict(X_test)\n",
    "predictions = pd.DataFrame({'class': X_test.flatten(), 'predict_proba': clf.predict_proba(X_test)[:,1],\n",
    "                            'predict': Y_predict, 'survived': Y_test})\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "print('Accuracy:', accuracy_score(Y_predict, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-airport",
   "metadata": {},
   "source": [
    "# Gaussian Bayes\n",
    "\n",
    "## 手工"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "clean-trading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Foot_Size</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.00</td>\n",
       "      <td>180</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.92</td>\n",
       "      <td>190</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.58</td>\n",
       "      <td>170</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.92</td>\n",
       "      <td>165</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.00</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.50</td>\n",
       "      <td>150</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.42</td>\n",
       "      <td>130</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.75</td>\n",
       "      <td>150</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Height  Weight  Foot_Size  Gender\n",
       "0    6.00     180         12       0\n",
       "1    5.92     190         11       0\n",
       "2    5.58     170         12       0\n",
       "3    5.92     165         10       0\n",
       "4    5.00     100          6       1\n",
       "5    5.50     150          8       1\n",
       "6    5.42     130          7       1\n",
       "7    5.75     150          9       1"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "data['Height'] = [6,5.92,5.58,5.92,5,5.5,5.42,5.75]\n",
    "data['Weight'] = [180,190,170,165,100,150,130,150]\n",
    "data['Foot_Size'] = [12,11,12,10,6,8,7,9]\n",
    "data['Gender'] = [0,0,0,0,1,1,1,1]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "juvenile-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_density(std, mean, x):\n",
    "    return 1 / np.sqrt(2 * np.pi * np.power(std, 2)) * np.exp(- np.power(x - mean, 2) / (2 * np.power(std, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "useful-cologne",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.5)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_c0 = np.mean(data['Gender'] == 0)\n",
    "p_c1 = np.mean(data['Gender'] == 1)\n",
    "\n",
    "p_c0, p_c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "fatty-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_c0_mean = np.mean(data['Height'][data['Gender']==0])\n",
    "x1_c0_std = np.std(data['Height'][data['Gender']==0])\n",
    "\n",
    "x2_c0_mean = np.mean(data['Weight'][data['Gender']==0])\n",
    "x2_c0_std = np.std(data['Weight'][data['Gender']==0])\n",
    "\n",
    "x3_c0_mean = np.mean(data['Foot_Size'][data['Gender']==0])\n",
    "x3_c0_std = np.std(data['Foot_Size'][data['Gender']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "false-nightmare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.855, 0.16209565077447324, 176.25, 9.60143218483576, 11.25, 0.82915619758885)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_c0_mean, x1_c0_std, x2_c0_mean, x2_c0_std, x3_c0_mean, x3_c0_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "amino-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_c1_mean = np.mean(data['Height'][data['Gender']==1])\n",
    "x1_c1_std = np.std(data['Height'][data['Gender']==1])\n",
    "\n",
    "x2_c1_mean = np.mean(data['Weight'][data['Gender']==1])\n",
    "x2_c1_std = np.std(data['Weight'][data['Gender']==1])\n",
    "\n",
    "x3_c1_mean = np.mean(data['Foot_Size'][data['Gender']==1])\n",
    "x3_c1_std = np.std(data['Foot_Size'][data['Gender']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "qualified-citizen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.4175, 0.2700347199898561, 132.5, 20.463381929681123, 7.5, 1.118033988749895)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_c1_mean, x1_c1_std, x2_c1_mean, x2_c1_std, x3_c1_mean, x3_c1_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "specialized-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def prob(x):\n",
    "    p1_c0 = norm(loc=x1_c0_mean, scale=x1_c0_std).cdf(x[0])\n",
    "    p2_c0 = norm(loc=x2_c0_mean, scale=x2_c0_std).cdf(x[1])\n",
    "    p3_c0 = norm(loc=x3_c0_mean, scale=x3_c0_std).cdf(x[2])\n",
    "    \n",
    "    p_c0_x = np.log(p_c0 * p1_c0 * p2_c0 * p3_c0)\n",
    "    print('p_c0_x', p_c0_x)\n",
    "    \n",
    "    p1_c1 = norm(loc=x1_c1_mean, scale=x1_c1_std).cdf(x[0])\n",
    "    p2_c1 = norm(loc=x2_c1_mean, scale=x2_c1_std).cdf(x[1])\n",
    "    p3_c1 = norm(loc=x3_c1_mean, scale=x3_c1_std).cdf(x[2])\n",
    "    \n",
    "    p_c1_x = np.log(p_c1 * p1_c1 * p2_c1 * p3_c1)\n",
    "    print('p_c1_x', p_c1_x)\n",
    "    \n",
    "    if p_c0_x > p_c1_x:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "caring-resource",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Foot_Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.67</td>\n",
       "      <td>145</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.00</td>\n",
       "      <td>110</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Height  Weight  Foot_Size\n",
       "0    5.67     145         12\n",
       "1    5.00     110          7"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.DataFrame({'Height':[5.67,5],'Weight':[145,110],'Foot_Size':[12,7]})\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "civic-freeware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_c0_x [-10.43390438]\n",
      "p_c1_x [-1.20100105]\n",
      "p_c0_x [-59.6193082]\n",
      "p_c1_x [-6.60285434]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = []\n",
    "for i in range(test_data.shape[0]):\n",
    "    row = test_data[i:i+1]\n",
    "    x = (row['Height'], row['Weight'], row['Foot_Size'])\n",
    "    predict.append(prob(x)) \n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "canadian-generation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Height  Weight  Foot_Size  Gender\n",
      "0    5.67     145         12       1\n",
      "1    5.00     110          7       1\n"
     ]
    }
   ],
   "source": [
    "test_results = pd.DataFrame({'Gender': predict})\n",
    "print(test_data.join(test_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-senate",
   "metadata": {},
   "source": [
    "## 自动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "valid-decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "\n",
    "X_train = data[['Height', 'Weight', 'Foot_Size']]\n",
    "Y_train = [0,0,0,0,1,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "endless-grain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "particular-karaoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of parameters of our model: \n",
      "\tClasses to predict:  [0 1]\n",
      "\tPrior on each class:  [0.5 0.5]\n",
      "\tMeans for each feature in each class:\n",
      " [[  5.855  176.25    11.25  ]\n",
      " [  5.4175 132.5      7.5   ]]\n",
      "\tStandard deviation for feature in each class: \n",
      " [[2.62757340e-02 9.21875007e+01 6.87500734e-01]\n",
      " [7.29194840e-02 4.18750001e+02 1.25000073e+00]]\n"
     ]
    }
   ],
   "source": [
    "print('Summary of parameters of our model: ')\n",
    "print('\\tClasses to predict: ', clf.classes_)\n",
    "print('\\tPrior on each class: ', clf.class_prior_)\n",
    "print('\\tMeans for each feature in each class:\\n', clf.theta_)\n",
    "print('\\tStandard deviation for feature in each class: \\n', clf.sigma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "drawn-biodiversity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some sample predictions:\n",
      "   Height  Weight  Foot_Size  gender\n",
      "0    5.67     145         12       0\n",
      "1    5.00     110          7       1\n"
     ]
    }
   ],
   "source": [
    "print('Some sample predictions:')\n",
    "test_data = pd.DataFrame({'Height':[5.67,5],'Weight':[145,110],'Foot_Size':[12,7]})\n",
    "test_results = pd.DataFrame({'gender': clf.predict(test_data)})\n",
    "print(test_data.join(test_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
